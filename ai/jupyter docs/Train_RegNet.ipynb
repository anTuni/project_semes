{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SUQhhPWPrZKd"
      },
      "source": [
        "# [SEMES] - 볼트 이상진단 - RegNet model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "elMHFSjb490R"
      },
      "source": [
        "#### model 학습을 진행할 때 필요한 라이브러리 import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K4OUeNTH2ihn"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "\n",
        "# 파이토치의 핵심 패키지(모델 구성 및 학습 등을 수행할 수 있는 기능을 제공)\n",
        "import torch\n",
        "# PyTorch에서 제공하는 신경망 모듈\n",
        "import torch.nn as nn\n",
        "# 학습에 사용되는 최적화 알고리즘\n",
        "import torch.optim as optim\n",
        "# PyTorch에서 이미지 데이터 처리와 관련된 함수와 모델들을 제공\n",
        "import torchvision import models, datasets\n",
        "# transforms 모듈은 데이터 전처리를 위한 함수들을 제공\n",
        "import torchvision.transforms as transforms\n",
        "# torchsummary는 PyTorch 모델의 요약 정보를 출력하는 라이브러리 / summary(model)로 요청\n",
        "from torchsummary import summary\n",
        "# DataLoader를 이용하여 데이터셋에서 미니배치(minibatch)를 추출 \n",
        "from torch.utils.data import DataLoader\n",
        "# 시간과 관련된 함수를 제공\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egHCCPTm5G2T"
      },
      "source": [
        "#### GPU 사용을 위한 설정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TOq_wFoqx3Qo"
      },
      "outputs": [],
      "source": [
        "# GPU가 사용 가능한 경우 cuda 사용 / GPU가 사용 불가능한 경우 CPU로 초기화하여 CPU 사용\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda:5\")\n",
        "    print(\"GPU is available. Using cuda\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"GPU is not available. Using CPU instead.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bj4x_T3A8vpj"
      },
      "source": [
        "#### 데이터 전처리"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cJiJmC2O80m4"
      },
      "outputs": [],
      "source": [
        "# 학습데이터 전처리\n",
        "train_transform = transforms.Compose([\n",
        "    # 해상도를 (224,224)로 맞춰준다 (a fixed resolution of 224×224 is best, even at higher flops : [논문]Designing Network Design Spaces - [저자]Facebook AI Research (FAIR))\n",
        "    transforms.Resize((224, 224)),\n",
        "    # 이미지를 좌우로 뒤집어서 데이터 증강(augmentation)을 수행(확률을 높여준)\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    # 이미지를 PyTorch의 Tensor로 변환\n",
        "    transforms.ToTensor(),\n",
        "    # 흑백 이미지이기 때문에 1개의 채널을 정규화(흑백이미지는 보통 (평균 : 0.5 / 표준편차 : 0.5)로 정규화)\n",
        "    transforms.Normalize([0.5], [0.5])\n",
        "])\n",
        "\n",
        "# 테스트데이터 전처리\n",
        "test_transform = transforms.Compose([\n",
        "    # 해상도를 (224,224)로 맞춰준다\n",
        "    transforms.Resize((224, 224)),\n",
        "    # 이미지를 PyTorch의 Tensor로 변환\n",
        "    transforms.ToTensor(),\n",
        "    # 흑백 이미지이기 때문에 1개의 채널을 정규화\n",
        "    transforms.Normalize([0.5], [0.5])\n",
        "])\n",
        "\n",
        "# 데이터가 저장된 경로\n",
        "data_dir = './semes_bolt'\n",
        "print(os.path.join(data_dir, 'train'))\n",
        "\n",
        "# 데이터가 저장된 경로에서 ImageFolder를 이용하여 이미지 데이터셋을 전처리한 후 로드(transforms_*==전처리 수행)\n",
        "train_datasets = datasets.ImageFolder(os.path.join(data_dir, 'train'), train_transform)\n",
        "test_datasets = datasets.ImageFolder(os.path.join(data_dir, 'test'), test_transform)\n",
        "\n",
        "# DataLoader를 이용 / 데이터셋에서 미니배치(minibatch)를 추출 \n",
        "# (batch_size==미니배치의 크기 / shuffle==데이터셋을 섞을지 여부 / num_workers==데이터셋을 불러올 때 사용할 프로세스 수)\n",
        "train_loader = DataLoader(train_datasets, batch_size=128, shuffle=True, num_workers=4)\n",
        "test_loader = DataLoader(test_datasets, batch_size=128, shuffle=True, num_workers=4)\n",
        "\n",
        "# 수행 결과를 출력\n",
        "print('학습 데이터셋 크기:', len(train_datasets))\n",
        "print('테스트 데이터셋 크기:', len(test_datasets))\n",
        "\n",
        "# 학습된 클래스 이름과 수행 결과를 출력\n",
        "class_names = train_datasets.classes\n",
        "print('클래스:', class_names)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### RegNet_Y_1.6 모델 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# RegNetY-16GF 모델 정의\n",
        "model = torch.hub.load('facebookresearch/pytorchvideo', 'pytorchvideo_regnetx_16gf_kinetics400')\n",
        "\n",
        "# 불러온 네트워크 모델의 출력 뉴런 수를 저장\n",
        "num_features = model.fc.in_features\n",
        "# 새로운 Fully Connected 레이어 추가\n",
        "model.fc = nn.Linear(num_features, 3)\n",
        "\n",
        "# GPU를 사용하기 위해 모델을 CUDA 디바이스로 보냄\n",
        "model.to(device)\n",
        "\n",
        "# 손실 함수와 최적화 알고리즘 정의\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
